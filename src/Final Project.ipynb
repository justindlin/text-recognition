{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as pl\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Reshape, Flatten, Dense, Conv2D, Dropout\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from numpy import newaxis\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populating x_train and y_train with imgs and corresponding value from dataset\n",
    "\n",
    "def populate(items):\n",
    "    x_arr = []\n",
    "    y_arr = []\n",
    "    counter = 36\n",
    "\n",
    "    for path in glob.glob(\"by_class/*\"):\n",
    "        for x in range(items):\n",
    "            imgName = glob.glob(path + \"/hsf_0/*.png\")[x]\n",
    "            img = cv2.imread(imgName, 0)\n",
    "            \n",
    "            newDim = (64,64)\n",
    "            img = cv2.resize(img, newDim, interpolation = cv2.INTER_AREA)\n",
    "            x_arr.append(img)\n",
    "            \n",
    "            # each folder name is the ascii value of the character \n",
    "            # -48 since 0 is the lowest ascii value we evaluate and it starts at 48\n",
    "            y_arr.append((int(path[9:])-48))\n",
    "        counter -= 1\n",
    "        print(counter)\n",
    "    \n",
    "    #converting to numpy array\n",
    "    x_train = np.array(x_arr)\n",
    "    y_train = np.array(y_arr)\n",
    "    \n",
    "    #normalizing data\n",
    "    x_train = x_train/255\n",
    "\n",
    "    return (x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "34\n",
      "33\n",
      "32\n",
      "31\n",
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "21\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 61, 61, 64)        1088      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 64)        65600     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 128)       131200    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 128)       262272    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 9, 9, 256)         524544    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 256)         1048832   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 43)                99115     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 43)                1892      \n",
      "=================================================================\n",
      "Total params: 2,134,543\n",
      "Trainable params: 2,134,543\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#populating training data and shuffling\n",
    "x_train, y_train = populate(150)\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=0)\n",
    "\n",
    "#creating a keras model using mostly convolution networks and dropouts\n",
    "model = Sequential([\n",
    "    Input((64, 64)),\n",
    "    Reshape((64,64,1)),\n",
    "    Conv2D(64, kernel_size=4, strides=1, activation='relu'),\n",
    "    Conv2D(64, kernel_size=4, strides=2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(128, kernel_size=4, strides=1, activation='relu'),\n",
    "    Conv2D(128, kernel_size=4, strides=2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(256, kernel_size=4, strides=1, activation='relu'),\n",
    "    Conv2D(256, kernel_size=4, strides=2, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(43, activation='relu'),\n",
    "    Dense(43, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss=sparse_categorical_crossentropy, optimizer=Adam(0.001), metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4860 samples, validate on 540 samples\n",
      "Epoch 1/5\n",
      "4860/4860 [==============================] - 165s 34ms/sample - loss: 3.6922 - acc: 0.0265 - val_loss: 3.5750 - val_acc: 0.0333\n",
      "Epoch 2/5\n",
      "4860/4860 [==============================] - 163s 34ms/sample - loss: 2.7057 - acc: 0.2471 - val_loss: 1.4655 - val_acc: 0.5833\n",
      "Epoch 3/5\n",
      "4860/4860 [==============================] - 161s 33ms/sample - loss: 1.2786 - acc: 0.6360 - val_loss: 0.7708 - val_acc: 0.7759\n",
      "Epoch 4/5\n",
      "4860/4860 [==============================] - 163s 34ms/sample - loss: 0.7760 - acc: 0.7689 - val_loss: 0.5891 - val_acc: 0.8352\n",
      "Epoch 5/5\n",
      "4860/4860 [==============================] - 167s 34ms/sample - loss: 0.5870 - acc: 0.8167 - val_loss: 0.5077 - val_acc: 0.8426\n"
     ]
    }
   ],
   "source": [
    "#5 repetitions, 10% of data as validation training data\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_split=0.1).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feeding an image to the model and making a prediction\n",
    "\n",
    "def predict(img):\n",
    "    \n",
    "    newDim = (64, 64)\n",
    "    img = cv2.resize(img, newDim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    #input expects shape (1, 64, 64) so newaxis is needed to change shape\n",
    "    img = img[newaxis,:,:]\n",
    "    prediction = model.predict_classes(img)\n",
    "    \n",
    "    #adding 48 since we removed 48 to reduce output possibilities\n",
    "    return chr((prediction+48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading a file and performing preprocessing on it. greyscale -> thresholding -> bilateral filtering\n",
    "\n",
    "filename = 'cat.jpeg'\n",
    "\n",
    "img = cv2.imread(filename)\n",
    "\n",
    "imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(imgray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "bilateral = cv2.bilateralFilter(thresh, 15, 75, 75) \n",
    "\n",
    "#getting contours\n",
    "contours, hierarchy = cv2.findContours(bilateral, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iterating through each contour\n",
    "for x in range(len(contours)):\n",
    "    [x, y, w, h] = cv2.boundingRect(contours[x])\n",
    "    \n",
    "    #disregarding very small contours\n",
    "    if w < 35 and h < 35:\n",
    "            continue\n",
    "     \n",
    "    #adding padding to the bounds\n",
    "    y=int(y-(h/3))\n",
    "    x=int(x-(w/3))\n",
    "    \n",
    "    w=int(w+(w/3)*2)\n",
    "    h=int(h+(h/3)*2)\n",
    "    \n",
    "    #drawing rect boundaries around characters\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    crop_img = bilateral[y:y+h, x:x+w]\n",
    "    \n",
    "    text = predict(crop_img)\n",
    "    \n",
    "    #drawing the prediction near each character\n",
    "    image = cv2.putText(img, text, (x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255) , 2, cv2.LINE_AA) \n",
    "    \n",
    "#creating new file with predictions\n",
    "cv2.imwrite('cat_prediction.jpeg', img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
